{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a stream of words, then skipgram pairs, then training batches based on the input file.\n",
    "These streams are built on-demand (see: Python generators) so the whole file does not have to be read into memory at once, allowing training on big datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stream(file_name, buf_bytes=1000000):\n",
    "    with open(file_name, \"r\") as f:\n",
    "        chars = f.read(buf_bytes)\n",
    "        max_index = 1\n",
    "        while max_index != 0:\n",
    "            max_index = 0\n",
    "            for match in re.finditer(\"([a-z]+)\\\\s\", chars):\n",
    "                yield match.group(1)\n",
    "                max_index = match.end(0)\n",
    "            chars = chars[max_index:] + f.read(buf_bytes)\n",
    "        if re.match(\"[a-z]+\", chars):\n",
    "            yield chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary_statistics(word_stream):\n",
    "    words = sorted(list(set(word_stream)))\n",
    "    stats = {}\n",
    "    for i, w in enumerate(words):\n",
    "        stats[i] = w\n",
    "        stats[w] = i\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_stream(word_stream, stats):\n",
    "    for w in word_stream:\n",
    "        yield stats[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipgram_pair_stream(stream, window_size):\n",
    "    buffer = list(itertools.islice(stream, window_size + 1))\n",
    "    pointer = 0\n",
    "    while pointer < len(buffer):\n",
    "        for i in range(-window_size, window_size + 1):\n",
    "            other = pointer + i\n",
    "            if other < 0 or other >= len(buffer) or other == pointer:\n",
    "                continue\n",
    "            yield (buffer[pointer], buffer[other])\n",
    "        # append next of stream to head of buffer (if available)\n",
    "        try:\n",
    "            buffer.append(next(stream))\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        # move center point to the head\n",
    "        pointer += 1\n",
    "        # remove from tail if no longer needed\n",
    "        if pointer > window_size:\n",
    "            buffer.pop(0)\n",
    "            pointer -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_batch_stream(skipgram_stream, batch_size, cache_size=100000):\n",
    "    cache = list(itertools.islice(skipgram_stream, cache_size))\n",
    "    while True:\n",
    "        for i in range(0, len(cache) - batch_size + 1, batch_size):\n",
    "            block = cache[i:i + batch_size]\n",
    "            inputs = [pair[0] for pair in block]\n",
    "            targets = [pair[1] for pair in block]\n",
    "            yield (inputs, targets)\n",
    "        cache = cache[len(cache) - (len(cache) % batch_size):]\n",
    "        new_elements = list(itertools.islice(skipgram_stream, cache_size))\n",
    "        cache += new_elements\n",
    "        if len(new_elements) == 0:\n",
    "            break\n",
    "    if len(cache) > 0:\n",
    "        inputs = [pair[0] for pair in cache]\n",
    "        targets = [pair[1] for pair in cache]\n",
    "        yield (inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_stream(text_file_name, stats, window_size, batch_size):\n",
    "    w_stream = word_stream(text_file_name)\n",
    "    i_stream = int_stream(w_stream, stats)\n",
    "    sgp_stream = skipgram_pair_stream(i_stream, window_size)\n",
    "    batch_stream = training_batch_stream(sgp_stream, batch_size)\n",
    "    return batch_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the TensorFlow execution graph for the neural network. The network is fed a list (batch) of input classes and a list of target classes (in the form of 1d vectors of word indices). The result is a 1d vector of the loss for each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(vocab_size, embedding_size, num_samples):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # input and target output are passed into the network via these placeholders and feed_dict\n",
    "    inputs_placeholder = tf.placeholder(shape=(None, ), dtype=tf.int32)\n",
    "    targets_placeholder = tf.placeholder(shape=(None, None), dtype=tf.int32)\n",
    "    \n",
    "    weights_initializer = tf.random_uniform_initializer(minval=-0.05, maxval=0.05)\n",
    "    # weights of input -> hidden (embeddings matrix)\n",
    "    weights_1 = tf.get_variable(\"weights_1\", shape=(vocab_size, embedding_size),\n",
    "                                dtype=tf.float32, initializer=weights_initializer)\n",
    "    # weights of hidden -> output\n",
    "    #weights_2 = tf.get_variable(\"weights_2\", shape=(embedding_size, vocab_size),\n",
    "    #                            dtype=tf.float32, initializer=weights_initializer)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Network input is a 1d vector of word indices\n",
    "    # convert to a 2d matrix of 1-hot vectors\n",
    "    #net_inputs = tf.one_hot(inputs_placeholder, depth=vocab_size)\n",
    "    # multiply with embedding matrix\n",
    "    #net_mul1 = tf.matmul(net_inputs, weights_1)\n",
    "    net_mul1 = tf.nn.embedding_lookup(weights_1, inputs_placeholder)\n",
    "    \n",
    "    # use sampled softmax loss (number of samples specified)\n",
    "    if num_samples is not None:\n",
    "        weights_2 = tf.get_variable(\"weights_2\", shape=(vocab_size, embedding_size),\n",
    "                                    dtype=tf.float32, initializer=weights_initializer)\n",
    "        zero_bias = tf.zeros(vocab_size, dtype=tf.float32)\n",
    "        #w2_transposed = tf.transpose(weights_2)\n",
    "        loss = tf.nn.sampled_softmax_loss(inputs=net_mul1, weights=weights_2, biases=zero_bias,\n",
    "                                          labels=targets_placeholder, num_sampled=num_samples, \n",
    "                                          num_classes=vocab_size)\n",
    "    # use regular softmax loss (no number of samples specified)\n",
    "    else:\n",
    "        weights_2 = tf.get_variable(\"weights_2\", shape=(embedding_size, vocab_size),\n",
    "                                    dtype=tf.float32, initializer=weights_initializer)\n",
    "        net_output = tf.matmul(net_mul1, weights_2)\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=targets_placeholder,\n",
    "                                                              logits=net_output)\n",
    "    \n",
    "    # return only what is necessary\n",
    "    # input and target placeholders are for feeding data\n",
    "    # loss is connected to an optimizer which works its way back to the weights to adjust them\n",
    "    # weights_1 is the embedding matrix containing the word embeddings\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return (inputs_placeholder, targets_placeholder, loss, weights_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(inputs_placeholder, targets_placeholder, weights_1, loss,\n",
    "                  train_stream_builder, epochs, learning_rate, total_pairs,\n",
    "                  words):\n",
    "    print(\"training started\")\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "    time_baseline = time.time()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for e in range(epochs):\n",
    "            batch_count, pairs_count, sum_loss = 0, 0, 0.0\n",
    "            for batch_inputs, batch_targets in train_stream_builder():\n",
    "                batch_inputs_np = np.array(batch_inputs)\n",
    "                batch_targets_np = np.array(batch_targets)[:, None]\n",
    "                #print(batch_inputs_np)\n",
    "                #print(batch_targets_np)\n",
    "                feed_dict = {inputs_placeholder: batch_inputs_np, targets_placeholder: batch_targets_np}\n",
    "                time_start = time.time()\n",
    "                sess.run(optimizer, feed_dict=feed_dict)\n",
    "                time_end = time.time()\n",
    "                batch_count += 1\n",
    "                pairs_count += len(batch_inputs)\n",
    "                batch_loss = sess.run(tf.reduce_mean(loss), feed_dict=feed_dict)\n",
    "                sum_loss += batch_loss\n",
    "                if time.time() - time_baseline >= 10.0:\n",
    "                    status_info = \"{}/{} pairs, avg loss: {:.5f}, time per batch: {:.5f}s\"\n",
    "                    status_info = status_info.format(pairs_count, total_pairs,\n",
    "                                                     sum_loss / float(batch_count),\n",
    "                                                     time_end - time_start)\n",
    "                    print(status_info)\n",
    "                    test_analogies_quality(words, sess.run(weights_1))\n",
    "                    print()\n",
    "                    time_baseline = time.time()\n",
    "        print(\"training complete\")\n",
    "        return sess.run(weights_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(words, embeddings_matrix, dot_size=1):\n",
    "    tsne = TSNE(n_components=2, random_state=1)\n",
    "    embeddings_matrix_2d = tsne.fit_transform(embeddings_matrix)\n",
    "    %matplotlib notebook\n",
    "    plt.scatter(embeddings_matrix_2d[:,0], embeddings_matrix_2d[:,1], s=dot_size)\n",
    "    for i, word in enumerate(words):\n",
    "        plt.text(embeddings_matrix_2d[i][0], embeddings_matrix_2d[i][1], word)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_term(s):\n",
    "    term = []\n",
    "    for m in re.finditer(\"(\\\\+|-)?(\\\\w+)\", s):\n",
    "        word, symbol = m.group(2), m.group(1)\n",
    "        if symbol is None or symbol == \"+\":\n",
    "            factor = 1\n",
    "        elif symbol == \"-\":\n",
    "            factor = -1\n",
    "        else:\n",
    "            raise ValueError(\"invalid symbol\")\n",
    "        term.append((word, factor))\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_sum(words, embeddings_matrix, term):\n",
    "    vector = np.zeros(len(embeddings_matrix[0]), dtype=np.float32)\n",
    "    for word, factor in term:\n",
    "        vector += embeddings_matrix[words.index(word)] * factor\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarities(words, embeddings_matrix, vector):\n",
    "    similarities = []\n",
    "    for i, word in enumerate(words):\n",
    "        embedding = embeddings_matrix[i]\n",
    "        similarity = embedding.dot(vector) / (np.linalg.norm(embedding) * np.linalg.norm(vector))\n",
    "        similarities.append((word, similarity))\n",
    "    return sorted(similarities, key = lambda s : -s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarities_s(words, embeddings_matrix, s):\n",
    "    term = parse_term(s)\n",
    "    term_words = [t[0] for t in term]\n",
    "    vector = embedding_sum(words, embeddings_matrix, term)\n",
    "    similarities = cosine_similarities(words, embeddings_matrix, vector)\n",
    "    similarities = [s for s in similarities if s[0] not in term_words]\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_analogies_quality(words, embeddings_matrix):\n",
    "    test_words = [\"man\", \"his\", \"north\", \"one\", \"green\", \"king\"]\n",
    "    for tw in test_words:\n",
    "        similarities = cosine_similarities_s(words, embeddings_matrix, tw)\n",
    "        similarities_short = [s[0] for s in similarities[:5]]\n",
    "        print(\"'{}': {}\".format(tw, similarities_short))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file_name = \"text8\"\n",
    "window_size = 5\n",
    "batch_size = 1000\n",
    "embedding_size = 128\n",
    "num_samples = 1\n",
    "epochs = 1\n",
    "learning_rate = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  253854\n"
     ]
    }
   ],
   "source": [
    "stats = vocabulary_statistics(word_stream(text_file_name))\n",
    "words = sorted(list(set(word_stream(text_file_name))))\n",
    "train_pairs_estimated = sum(2 * window_size for w in word_stream(text_file_name))\n",
    "train_stream_builder = lambda : build_training_stream(text_file_name, stats, window_size, batch_size)\n",
    "vocab_size = len(words)\n",
    "print(\"vocab size: \", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training started\n",
      "15000/170052070 pairs, avg loss: 0.31240, time per batch: 0.57898s\n",
      "'man': ['august', 'the', 'individualist', 'of', 'to']\n",
      "'his': ['he', 'one', 'property', 'the', 'that']\n",
      "'north': ['piron', 'schraufite', 'backflips', 'hung', 'cocoanut']\n",
      "'one': ['he', 'his', 'the', 'property', 'which']\n",
      "'green': ['aaas', 'tetons', 'derbies', 'bichat', 'uznam']\n",
      "'king': ['abuse', 'ruler', 'been', 'chief', 'belief']\n",
      "\n",
      "32000/170052070 pairs, avg loss: 0.28217, time per batch: 0.60257s\n",
      "'man': ['expound', 'greene', 'doctrine', 'august', 'now']\n",
      "'his': ['one', 'the', 'nine', 'he', 'that']\n",
      "'north': ['institute', 'prior', 'syndicalism', 'power', 'include']\n",
      "'one': ['the', 'nine', 'to', 'in', 'that']\n",
      "'green': ['aaas', 'tetons', 'derbies', 'bichat', 'uznam']\n",
      "'king': ['abuse', 'ruler', 'chief', 'belief', 'still']\n",
      "\n",
      "49000/170052070 pairs, avg loss: 0.25875, time per batch: 0.55599s\n",
      "'man': ['expound', 'william', 'greene', 'doctrine', 'now']\n",
      "'his': ['one', 'nine', 'he', 'the', 'state']\n",
      "'north': ['include', 'who', 'syndicalism', 'helped', 'spanish']\n",
      "'one': ['nine', 'the', 'to', 'was', 'in']\n",
      "'green': ['patriarchy', 'united', 'fascist', 'feminism', 'creation']\n",
      "'king': ['abuse', 'ruler', 'chief', 'still', 'pejorative']\n",
      "\n",
      "67000/170052070 pairs, avg loss: 0.23169, time per batch: 0.57741s\n",
      "'man': ['expound', 'william', 'greene', 'doctrine', 'liberty']\n",
      "'his': ['he', 'property', 'state', 'was', 'factories']\n",
      "'north': ['subsequent', 'include', 'culture', 'federation', 'who']\n",
      "'one': ['nine', 'the', 'was', 'his', 'to']\n",
      "'green': ['patriarchy', 'united', 'synthesis', 'civilization', 'classical']\n",
      "'king': ['chief', 'abuse', 'ruler', 'still', 'pejorative']\n",
      "\n",
      "84000/170052070 pairs, avg loss: 0.21258, time per batch: 0.69271s\n",
      "'man': ['expound', 'liberty', 'now', 'william', 'greene']\n",
      "'his': ['he', 'property', 'state', 'factories', 'so']\n",
      "'north': ['subsequent', 'include', 'culture', 'federation', 'psychiatric']\n",
      "'one': ['nine', 'his', 'zero', 'he', 'to']\n",
      "'green': ['patriarchy', 'neocolonialism', 'synthesis', 'united', 'classical']\n",
      "'king': ['chief', 'abuse', 'ruler', 'still', 'pejorative']\n",
      "\n",
      "100000/170052070 pairs, avg loss: 0.19799, time per batch: 0.56686s\n",
      "'man': ['expound', 'liberty', 'william', 'greene', 'now']\n",
      "'his': ['he', 'property', 'three', 'state', 'factories']\n",
      "'north': ['subsequent', 'include', 'culture', 'psychiatric', 'federation']\n",
      "'one': ['nine', 'his', 'he', 'three', 'zero']\n",
      "'green': ['neocolonialism', 'patriarchy', 'autistic', 'dr', 'list']\n",
      "'king': ['chief', 'abuse', 'ruler', 'pejorative', 'been']\n",
      "\n",
      "117000/170052070 pairs, avg loss: 0.18327, time per batch: 0.55863s\n",
      "'man': ['expound', 'liberty', 'william', 'now', 'globalization']\n",
      "'his': ['he', 'property', 'three', 'control', 'researchers']\n",
      "'north': ['subsequent', 'include', 'literate', 'culture', 'toddler']\n",
      "'one': ['nine', 'his', 'he', 'three', 'zero']\n",
      "'green': ['neocolonialism', 'patriarchy', 'dr', 'list', 'synthesis']\n",
      "'king': ['chief', 'abuse', 'ruler', 'pejorative', 'been']\n",
      "\n",
      "134000/170052070 pairs, avg loss: 0.17587, time per batch: 0.56504s\n",
      "'man': ['liberty', 'expound', 'william', 'now', 'globalization']\n",
      "'his': ['he', 'property', 'three', 'researchers', 'control']\n",
      "'north': ['subsequent', 'include', 'literate', 'allowing', 'toddler']\n",
      "'one': ['nine', 'his', 'he', 'in', 'three']\n",
      "'green': ['neocolonialism', 'patriarchy', 'list', 'dr', 'synthesis']\n",
      "'king': ['chief', 'abuse', 'ruler', 'pejorative', 'been']\n",
      "\n",
      "151000/170052070 pairs, avg loss: 0.16805, time per batch: 0.58683s\n",
      "'man': ['liberty', 'expound', 'william', 'now', 'globalization']\n",
      "'his': ['he', 'property', 'researchers', 'control', 'state']\n",
      "'north': ['subsequent', 'include', 'c', 'scientists', 'though']\n",
      "'one': ['nine', 'his', 'zero', 'he', 'in']\n",
      "'green': ['neocolonialism', 'patriarchy', 'list', 'dr', 'synthesis']\n",
      "'king': ['chief', 'abuse', 'ruler', 'pejorative', 'been']\n",
      "\n",
      "168000/170052070 pairs, avg loss: 0.16809, time per batch: 0.59240s\n",
      "'man': ['liberty', 'expound', 'william', 'globalization', 'educators']\n",
      "'his': ['he', 'had', 'property', 'one', 'nine']\n",
      "'north': ['c', 'preoccupied', 'offshore', 'britain', 'subsequent']\n",
      "'one': ['nine', 'he', 'his', 'zero', 'was']\n",
      "'green': ['neocolonialism', 'patriarchy', 'list', 'dr', 'regions']\n",
      "'king': ['chief', 'abuse', 'pejorative', 'been', 'belief']\n",
      "\n",
      "184000/170052070 pairs, avg loss: 0.16627, time per batch: 0.57428s\n",
      "'man': ['liberty', 'expound', 'william', 'globalization', 'educators']\n",
      "'his': ['nine', 'he', 'had', 'property', 'one']\n",
      "'north': ['html', 'offshore', 'c', 'preoccupied', 'britain']\n",
      "'one': ['nine', 'in', 'his', 'he', 'the']\n",
      "'green': ['neocolonialism', 'patriarchy', 'list', 'dr', 'regions']\n",
      "'king': ['chief', 'abuse', 'pejorative', 'been', 'belief']\n",
      "\n",
      "201000/170052070 pairs, avg loss: 0.16423, time per batch: 0.59967s\n",
      "'man': ['liberty', 'expound', 'william', 'globalization', 'educators']\n",
      "'his': ['nine', 'he', 'had', 'researchers', 'control']\n",
      "'north': ['mississippi', 'land', 'rudolf', 'c', 'along']\n",
      "'one': ['nine', 'in', 'his', 'seven', 'to']\n",
      "'green': ['neocolonialism', 'sequences', 'patriarchy', 'list', 'dr']\n",
      "'king': ['chief', 'abuse', 'pejorative', 'been', 'belief']\n",
      "\n",
      "218000/170052070 pairs, avg loss: 0.15629, time per batch: 0.58655s\n",
      "'man': ['walls', 'troy', 'shell', 'advance', 'evident']\n",
      "'his': ['he', 'nine', 'researchers', 'longest', 'measure']\n",
      "'north': ['mississippi', 'land', 'along', 'rudolf', 'c']\n",
      "'one': ['nine', 'in', 'to', 'seven', 'three']\n",
      "'green': ['sequences', 'neocolonialism', 'patriarchy', 'list', 'dr']\n",
      "'king': ['barasti', 'defined', 'differentiate', 'diagnostic', 'centre']\n",
      "\n",
      "235000/170052070 pairs, avg loss: 0.15249, time per batch: 0.58236s\n",
      "'man': ['walls', 'troy', 'evident', 'august', 'shell']\n",
      "'his': ['researchers', 'nine', 'measure', 'control', 'approach']\n",
      "'north': ['mississippi', 'land', 'rudolf', 'along', 'c']\n",
      "'one': ['nine', 'three', 'in', 'to', 'american']\n",
      "'green': ['sequences', 'neocolonialism', 'patriarchy', 'list', 'dr']\n",
      "'king': ['barasti', 'differentiate', 'diagnostic', 'indie', 'plant']\n",
      "\n",
      "252000/170052070 pairs, avg loss: 0.14612, time per batch: 0.55826s\n",
      "'man': ['democracy', 'imposed', 'decision', 'troy', 'construction']\n",
      "'his': ['researchers', 'nine', 'control', 'measure', 'approach']\n",
      "'north': ['mississippi', 'land', 'rudolf', 'along', 'camel']\n",
      "'one': ['nine', 'in', 'american', 'three', 'that']\n",
      "'green': ['sequences', 'neocolonialism', 'opportunity', 'patriarchy', 'list']\n",
      "'king': ['barasti', 'differentiate', 'diagnostic', 'indie', 'plant']\n",
      "\n",
      "269000/170052070 pairs, avg loss: 0.14325, time per batch: 0.56998s\n",
      "'man': ['democracy', 'decision', 'imposed', 'company', 'good']\n",
      "'his': ['nine', 'turns', 'erected', 'where', 'took']\n",
      "'north': ['mississippi', 'rudolf', 'along', 'camel', 'land']\n",
      "'one': ['nine', 'in', 'stated', 'american', 'that']\n",
      "'green': ['opportunity', 'sequences', 'neocolonialism', 'patriarchy', 'list']\n",
      "'king': ['barasti', 'differentiate', 'diagnostic', 'indie', 'noticed']\n",
      "\n",
      "287000/170052070 pairs, avg loss: 0.13777, time per batch: 0.55162s\n",
      "'man': ['democracy', 'imposed', 'decision', 'company', 'good']\n",
      "'his': ['nine', 'turns', 'erected', 'researchers', 'collecting']\n",
      "'north': ['mississippi', 'rudolf', 'help', 'along', 'camel']\n",
      "'one': ['to', 'in', 'the', 'three', 'was']\n",
      "'green': ['opportunity', 'sequences', 'neocolonialism', 'patriarchy', 'list']\n",
      "'king': ['barasti', 'differentiate', 'chief', 'noticed', 'diagnostic']\n",
      "\n",
      "304000/170052070 pairs, avg loss: 0.13150, time per batch: 0.59183s\n",
      "'man': ['democracy', 'imposed', 'company', 'decision', 'senior']\n",
      "'his': ['collecting', 'researchers', 'nine', 'volume', 'changes']\n",
      "'north': ['along', 'rudolf', 'help', 'camel', 'alphabet']\n",
      "'one': ['in', 'the', 'to', 'was', 'that']\n",
      "'green': ['opportunity', 'sequences', 'neocolonialism', 'patriarchy', 'list']\n",
      "'king': ['barasti', 'differentiate', 'noticed', 'diagnostic', 'indie']\n",
      "\n",
      "319000/170052070 pairs, avg loss: 0.12783, time per batch: 0.65568s\n",
      "'man': ['democracy', 'imposed', 'senior', 'company', 'decision']\n",
      "'his': ['agriculture', 'researchers', 'collecting', 'archaic', 'largest']\n",
      "'north': ['along', 'rudolf', 'camel', 'help', 'alphabet']\n",
      "'one': ['in', 'to', 'the', 'three', 'that']\n",
      "'green': ['opportunity', 'sequences', 'neocolonialism', 'patriarchy', 'list']\n",
      "'king': ['barasti', 'differentiate', 'noticed', 'diagnostic', 'indie']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336000/170052070 pairs, avg loss: 0.12275, time per batch: 0.56143s\n",
      "'man': ['democracy', 'imposed', 'senior', 'attack', 'company']\n",
      "'his': ['agriculture', 'researchers', 'largest', 'archaic', 'hometown']\n",
      "'north': ['along', 'rudolf', 'camel', 'alphabet', 'help']\n",
      "'one': ['in', 'three', 'the', 'to', 'that']\n",
      "'green': ['opportunity', 'sequences', 'neocolonialism', 'patriarchy', 'list']\n",
      "'king': ['barasti', 'differentiate', 'noticed', 'diagnostic', 'strategic']\n",
      "\n",
      "353000/170052070 pairs, avg loss: 0.12127, time per batch: 0.54936s\n",
      "'man': ['democracy', 'imposed', 'senior', 'company', 'decision']\n",
      "'his': ['agriculture', 'researchers', 'largest', 'archaic', 'existing']\n",
      "'north': ['rudolf', 'camel', 'alphabet', 'help', 'along']\n",
      "'one': ['in', 'three', 'to', 'the', 'that']\n",
      "'green': ['opportunity', 'sequences', 'neocolonialism', 'patriarchy', 'list']\n",
      "'king': ['ruler', 'defined', 'been', 'buoying', 'hugs']\n",
      "\n",
      "370000/170052070 pairs, avg loss: 0.11934, time per batch: 0.57397s\n",
      "'man': ['democracy', 'imposed', 'senior', 'decision', 'romans']\n",
      "'his': ['agriculture', 'largest', 'archaic', 'researchers', 'com']\n",
      "'north': ['rudolf', 'camel', 'alphabet', 'help', 'miles']\n",
      "'one': ['in', 'the', 'to', 'three', 'that']\n",
      "'green': ['opportunity', 'poetical', 'neocolonialism', 'sequences', 'patriarchy']\n",
      "'king': ['ruler', 'self', 'been', 'still', 'describe']\n",
      "\n",
      "386000/170052070 pairs, avg loss: 0.11836, time per batch: 0.59707s\n",
      "'man': ['evident', 'militia', 'romans', 'passage', 'imposed']\n",
      "'his': ['agriculture', 'largest', 'archaic', 'researchers', 'com']\n",
      "'north': ['rudolf', 'camel', 'alphabet', 'help', 'miles']\n",
      "'one': ['in', 'the', 'to', 'that', 'three']\n",
      "'green': ['opportunity', 'hierarchies', 'poetical', 'neocolonialism', 'understands']\n",
      "'king': ['self', 'ruler', 'been', 'describe', 'still']\n",
      "\n",
      "402000/170052070 pairs, avg loss: 0.11662, time per batch: 0.57323s\n",
      "'man': ['evident', 'passage', 'mexican', 'militia', 'insanity']\n",
      "'his': ['agriculture', 'largest', 'archaic', 'com', 'editorial']\n",
      "'north': ['rudolf', 'camel', 'alphabet', 'help', 'miles']\n",
      "'one': ['in', 'three', 'the', 'to', 'de']\n",
      "'green': ['hierarchies', 'opportunity', 'humanity', 'tyrranion', 'poetical']\n",
      "'king': ['self', 'ruler', 'been', 'describe', 'still']\n",
      "\n",
      "418000/170052070 pairs, avg loss: 0.11529, time per batch: 0.56219s\n",
      "'man': ['evident', 'passage', 'militia', 'mexican', 'insanity']\n",
      "'his': ['agriculture', 'largest', 'archaic', 'invited', 'bar']\n",
      "'north': ['rudolf', 'camel', 'miles', 'along', 'creek']\n",
      "'one': ['in', 'the', 'to', 'that', 'de']\n",
      "'green': ['hierarchies', 'humanity', 'opportunity', 'tyrranion', 'poetical']\n",
      "'king': ['denton', 'offutt', 'fisher', 'michigan', 'horns']\n",
      "\n",
      "434000/170052070 pairs, avg loss: 0.11334, time per batch: 0.55412s\n",
      "'man': ['good', 'evident', 'passage', 'militia', 'insanity']\n",
      "'his': ['agriculture', 'largest', 'archaic', 'invited', 'exclusion']\n",
      "'north': ['rudolf', 'camel', 'miles', 'creek', 'fits']\n",
      "'one': ['the', 'in', 'that', 'de', 'three']\n",
      "'green': ['hierarchies', 'ethologists', 'opportunity', 'humanity', 'tyrranion']\n",
      "'king': ['altruism', 'witnessed', 'utc', 'plain', 'ten']\n",
      "\n",
      "451000/170052070 pairs, avg loss: 0.11073, time per batch: 0.56296s\n",
      "'man': ['good', 'evident', 'passage', 'militia', 'insanity']\n",
      "'his': ['agriculture', 'largest', 'archaic', 'invited', 'exclusion']\n",
      "'north': ['rudolf', 'camel', 'miles', 'creek', 'fits']\n",
      "'one': ['the', 'in', 'that', 'to', 'de']\n",
      "'green': ['ethologists', 'hierarchies', 'opportunity', 'humanity', 'tyrranion']\n",
      "'king': ['organisms', 'utc', 'witnessed', 'plain', 'ten']\n",
      "\n",
      "467000/170052070 pairs, avg loss: 0.10845, time per batch: 0.56962s\n",
      "'man': ['good', 'evident', 'militia', 'insanity', 'passage']\n",
      "'his': ['largest', 'invited', 'religions', 'agriculture', 'exclusion']\n",
      "'north': ['rudolf', 'camel', 'miles', 'creek', 'fits']\n",
      "'one': ['the', 'in', 'to', 'that', 'three']\n",
      "'green': ['ethologists', 'hierarchies', 'opportunity', 'humanity', 'tyrranion']\n",
      "'king': ['organisms', 'received', 'utc', 'beyond', 'rider']\n",
      "\n",
      "483000/170052070 pairs, avg loss: 0.10917, time per batch: 0.55805s\n",
      "'man': ['good', 'worker', 'evident', 'animals', 'e']\n",
      "'his': ['reactions', 'sanctuary', 'offering', 'longest', 'np']\n",
      "'north': ['rudolf', 'camel', 'miles', 'creek', 'fits']\n",
      "'one': ['in', 'the', 'three', 'that', 'to']\n",
      "'green': ['ethologists', 'hierarchies', 'opportunity', 'humanity', 'tyrranion']\n",
      "'king': ['beyond', 'received', 'irving', 'organisms', 'utc']\n",
      "\n",
      "499000/170052070 pairs, avg loss: 0.10642, time per batch: 0.63439s\n",
      "'man': ['e', 'membership', 'worker', 'good', 'enjoyment']\n",
      "'his': ['rallied', 'reactions', 'achilles', 'languages', 'longest']\n",
      "'north': ['rudolf', 'camel', 'miles', 'reliance', 'creek']\n",
      "'one': ['in', 'the', 'three', 'that', 'to']\n",
      "'green': ['ethologists', 'committee', 'hierarchies', 'opportunity', 'humanity']\n",
      "'king': ['beyond', 'received', 'important', 'irving', 'organisms']\n",
      "\n",
      "516000/170052070 pairs, avg loss: 0.10551, time per batch: 0.55352s\n",
      "'man': ['e', 'membership', 'worker', 'good', 'enjoyment']\n",
      "'his': ['rallied', 'reactions', 'achilles', 'languages', 'selection']\n",
      "'north': ['rudolf', 'camel', 'miles', 'reliance', 'creek']\n",
      "'one': ['in', 'the', 'three', 'that', 'to']\n",
      "'green': ['committee', 'ethologists', 'hierarchies', 'humanity', 'tyrranion']\n",
      "'king': ['beyond', 'received', 'important', 'irving', 'organisms']\n",
      "\n",
      "533000/170052070 pairs, avg loss: 0.10333, time per batch: 0.55473s\n",
      "'man': ['curbed', 'e', 'membership', 'sahara', 'worker']\n",
      "'his': ['rallied', 'reactions', 'achilles', 'selection', 'languages']\n",
      "'north': ['creek', 'camel', 'miles', 'becoming', 'britain']\n",
      "'one': ['in', 'the', 'three', 'that', 'to']\n",
      "'green': ['committee', 'ethologists', 'hierarchies', 'humanity', 'tyrranion']\n",
      "'king': ['beyond', 'received', 'important', 'irving', 'organisms']\n",
      "\n",
      "549000/170052070 pairs, avg loss: 0.10222, time per batch: 0.55854s\n",
      "'man': ['curbed', 'jews', 'e', 'sahara', 'membership']\n",
      "'his': ['rallied', 'reactions', 'achilles', 'longest', 'forested']\n",
      "'north': ['arabic', 'youthful', 'policy', 'arrangement', 'london']\n",
      "'one': ['in', 'the', 'to', 'three', 'that']\n",
      "'green': ['committee', 'ethologists', 'hierarchies', 'humanity', 'tyrranion']\n",
      "'king': ['beyond', 'received', 'important', 'irving', 'organisms']\n",
      "\n",
      "566000/170052070 pairs, avg loss: 0.10346, time per batch: 0.62526s\n",
      "'man': ['curbed', 'jews', 'e', 'membership', 'citizens']\n",
      "'his': ['rallied', 'reactions', 'achilles', 'pacific', 'longest']\n",
      "'north': ['arabic', 'youthful', 'policy', 'california', 'founded']\n",
      "'one': ['in', 'the', 'to', 'three', 'nine']\n",
      "'green': ['committee', 'ethologists', 'hierarchies', 'humanity', 'tyrranion']\n",
      "'king': ['beyond', 'received', 'important', 'irving', 'organisms']\n",
      "\n",
      "582000/170052070 pairs, avg loss: 0.10111, time per batch: 0.66546s\n",
      "'man': ['curbed', 'jews', 'e', 'reader', 'membership']\n",
      "'his': ['daniels', 'rallied', 'pacific', 'reactions', 'longest']\n",
      "'north': ['arabic', 'makes', 'hands', 'youthful', 'pistol']\n",
      "'one': ['in', 'the', 'to', 'three', 'that']\n",
      "'green': ['committee', 'ethologists', 'hierarchies', 'humanity', 'tyrranion']\n",
      "'king': ['beyond', 'received', 'important', 'irving', 'organisms']\n",
      "\n",
      "597000/170052070 pairs, avg loss: 0.10022, time per batch: 0.66513s\n",
      "'man': ['curbed', 'jews', 'reader', 'e', 'membership']\n",
      "'his': ['daniels', 'mentioned', 'arrangement', 'sanctuary', 'james']\n",
      "'north': ['arabic', 'makes', 'hands', 'pistol', 'end']\n",
      "'one': ['in', 'the', 'to', 'three', 'that']\n",
      "'green': ['committee', 'ethologists', 'unknowingly', 'hierarchies', 'humanity']\n",
      "'king': ['beyond', 'received', 'important', 'irving', 'organisms']\n",
      "\n",
      "613000/170052070 pairs, avg loss: 0.09904, time per batch: 0.56839s\n",
      "'man': ['curbed', 'reader', 'jews', 'e', 'membership']\n",
      "'his': ['arrangement', 'james', 'town', 'begins', 'remain']\n",
      "'north': ['arabic', 'makes', 'pistol', 'end', 'youthful']\n",
      "'one': ['in', 'the', 'to', 'three', 'that']\n",
      "'green': ['unknowingly', 'committee', 'ethologists', 'hierarchies', 'humanity']\n",
      "'king': ['beyond', 'received', 'important', 'irving', 'organisms']\n",
      "\n",
      "629000/170052070 pairs, avg loss: 0.09765, time per batch: 0.56106s\n",
      "'man': ['reader', 'curbed', 'jews', 'e', 'membership']\n",
      "'his': ['arrangement', 'daniels', 'town', 'remain', 'summit']\n",
      "'north': ['arabic', 'makes', 'end', 'pistol', 'giving']\n",
      "'one': ['to', 'the', 'in', 'three', 'that']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'green': ['unknowingly', 'committee', 'ethologists', 'hierarchies', 'humanity']\n",
      "'king': ['beyond', 'important', 'irving', 'received', 'organisms']\n",
      "\n",
      "646000/170052070 pairs, avg loss: 0.09644, time per batch: 0.55740s\n",
      "'man': ['reader', 'curbed', 'jews', 'e', 'membership']\n",
      "'his': ['supply', 'arrangement', 'town', 'summit', 'remain']\n",
      "'north': ['giving', 'arabic', 'fully', 'end', 'pistol']\n",
      "'one': ['to', 'in', 'the', 'three', 'that']\n",
      "'green': ['unknowingly', 'committee', 'ethologists', 'hierarchies', 'humanity']\n",
      "'king': ['beyond', 'important', 'irving', 'received', 'organisms']\n",
      "\n",
      "662000/170052070 pairs, avg loss: 0.09531, time per batch: 0.57804s\n",
      "'man': ['reader', 'jews', 'curbed', 'e', 'membership']\n",
      "'his': ['supply', 'arrangement', 'town', 'street', 'skill']\n",
      "'north': ['giving', 'needed', 'arabic', 'end', 'pistol']\n",
      "'one': ['to', 'the', 'in', 'three', 'was']\n",
      "'green': ['unknowingly', 'committee', 'ethologists', 'diagnose', 'hendricks']\n",
      "'king': ['beyond', 'irving', 'received', 'price', 'organisms']\n",
      "\n",
      "677000/170052070 pairs, avg loss: 0.09400, time per batch: 0.55641s\n",
      "'man': ['reader', 'jews', 'curbed', 'e', 'membership']\n",
      "'his': ['supply', 'town', 'promising', 'arrangement', 'figure']\n",
      "'north': ['giving', 'needed', 'arabic', 'real', 'end']\n",
      "'one': ['to', 'the', 'three', 'in', 'was']\n",
      "'green': ['unknowingly', 'committee', 'ethologists', 'diagnose', 'hendricks']\n",
      "'king': ['beyond', 'irving', 'received', 'price', 'organisms']\n",
      "\n",
      "694000/170052070 pairs, avg loss: 0.09305, time per batch: 0.55049s\n",
      "'man': ['reader', 'jews', 'curbed', 'membership', 'owned']\n",
      "'his': ['supply', 'fate', 'figure', 'arrangement', 'town']\n",
      "'north': ['riches', 'medical', 'profited', 'rimland', 'ample']\n",
      "'one': ['to', 'the', 'three', 'nine', 'in']\n",
      "'green': ['unknowingly', 'committee', 'ethologists', 'diagnose', 'hendricks']\n",
      "'king': ['beyond', 'irving', 'received', 'price', 'organisms']\n",
      "\n",
      "710000/170052070 pairs, avg loss: 0.09186, time per batch: 0.57294s\n",
      "'man': ['reader', 'jews', 'curbed', 'membership', 'owned']\n",
      "'his': ['figure', 'supply', 'fate', 'arrangement', 'moe']\n",
      "'north': ['riches', 'canada', 'presents', 'rimland', 'medical']\n",
      "'one': ['to', 'three', 'nine', 'in', 'the']\n",
      "'green': ['unknowingly', 'committee', 'ethologists', 'diagnose', 'hendricks']\n",
      "'king': ['beyond', 'irving', 'received', 'verlag', 'price']\n",
      "\n",
      "727000/170052070 pairs, avg loss: 0.09159, time per batch: 0.55113s\n",
      "'man': ['reader', 'jews', 'curbed', 'membership', 'owned']\n",
      "'his': ['figure', 'supply', 'fate', 'arrangement', 'moe']\n",
      "'north': ['canada', 'presents', 'riches', 'rimland', 'medical']\n",
      "'one': ['to', 'three', 'nine', 'in', 'that']\n",
      "'green': ['unknowingly', 'committee', 'ethologists', 'diagnose', 'hendricks']\n",
      "'king': ['beyond', 'irving', 'verlag', 'received', 'price']\n",
      "\n",
      "743000/170052070 pairs, avg loss: 0.09067, time per batch: 0.55252s\n",
      "'man': ['reader', 'jews', 'curbed', 'membership', 'owned']\n",
      "'his': ['figure', 'supply', 'fate', 'arrangement', 'randal']\n",
      "'north': ['canada', 'presents', 'riches', 'rimland', 'medical']\n",
      "'one': ['to', 'three', 'nine', 'in', 'that']\n",
      "'green': ['unknowingly', 'committee', 'ethologists', 'diagnose', 'hendricks']\n",
      "'king': ['irving', 'verlag', 'received', 'organisms', 'friendly']\n",
      "\n",
      "759000/170052070 pairs, avg loss: 0.09003, time per batch: 0.55950s\n",
      "'man': ['reader', 'jews', 'curbed', 'membership', 'owned']\n",
      "'his': ['figure', 'supply', 'portions', 'visible', 'fate']\n",
      "'north': ['canada', 'presents', 'riches', 'rimland', 'humanity']\n",
      "'one': ['to', 'three', 'nine', 'in', 'the']\n",
      "'green': ['unknowingly', 'committee', 'ethologists', 'diagnose', 'hendricks']\n",
      "'king': ['irving', 'verlag', 'received', 'commentator', 'organisms']\n",
      "\n",
      "776000/170052070 pairs, avg loss: 0.08833, time per batch: 0.56411s\n",
      "'man': ['reader', 'jews', 'curbed', 'membership', 'owned']\n",
      "'his': ['figure', 'supply', 'plan', 'issues', 'fate']\n",
      "'north': ['canada', 'presents', 'riches', 'rimland', 'humanity']\n",
      "'one': ['to', 'nine', 'three', 'in', 'the']\n",
      "'green': ['unknowingly', 'committee', 'ethologists', 'diagnose', 'hendricks']\n",
      "'king': ['irving', 'verlag', 'received', 'commentator', 'organisms']\n",
      "\n",
      "792000/170052070 pairs, avg loss: 0.08749, time per batch: 0.55706s\n",
      "'man': ['reader', 'jews', 'curbed', 'membership', 'owned']\n",
      "'his': ['issues', 'figure', 'supply', 'plan', 'fate']\n",
      "'north': ['canada', 'presents', 'riches', 'rimland', 'humanity']\n",
      "'one': ['nine', 'three', 'in', 'to', 'than']\n",
      "'green': ['unknowingly', 'umbrella', 'committee', 'ethologists', 'diagnose']\n",
      "'king': ['irving', 'verlag', 'received', 'commentator', 'organisms']\n",
      "\n",
      "809000/170052070 pairs, avg loss: 0.08658, time per batch: 0.55156s\n",
      "'man': ['reader', 'jews', 'curbed', 'membership', 'owned']\n",
      "'his': ['gives', 'visible', 'determining', 'services', 'india']\n",
      "'north': ['canada', 'health', 'presents', 'riches', 'rimland']\n",
      "'one': ['in', 'nine', 'three', 'new', 'number']\n",
      "'green': ['unknowingly', 'umbrella', 'committee', 'ethologists', 'diagnose']\n",
      "'king': ['irving', 'verlag', 'received', 'commentator', 'organisms']\n",
      "\n",
      "825000/170052070 pairs, avg loss: 0.08710, time per batch: 0.56836s\n",
      "'man': ['reader', 'jews', 'curbed', 'membership', 'owned']\n",
      "'his': ['he', 'explains', 'members', 'head', 'gives']\n",
      "'north': ['canada', 'health', 'presents', 'riches', 'rimland']\n",
      "'one': ['in', 'nine', 'new', 'old', 'three']\n",
      "'green': ['unknowingly', 'umbrella', 'committee', 'ethologists', 'diagnose']\n",
      "'king': ['irving', 'verlag', 'received', 'commentator', 'organisms']\n",
      "\n",
      "841000/170052070 pairs, avg loss: 0.08623, time per batch: 0.59674s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'owned']\n",
      "'his': ['he', 'head', 'explains', 'spirit', 'members']\n",
      "'north': ['canada', 'health', 'presents', 'riches', 'rimland']\n",
      "'one': ['in', 'nine', 'provided', 'three', 'old']\n",
      "'green': ['unknowingly', 'umbrella', 'committee', 'ethologists', 'diagnose']\n",
      "'king': ['irving', 'verlag', 'received', 'commentator', 'organisms']\n",
      "\n",
      "857000/170052070 pairs, avg loss: 0.08802, time per batch: 0.56808s\n",
      "'man': ['reader', 'curbed', 'jews', 'owned', 'membership']\n",
      "'his': ['explains', 'affinity', 'gives', 'society', 'real']\n",
      "'north': ['canada', 'medical', 'health', 'presents', 'riches']\n",
      "'one': ['in', 'nine', 'new', 'old', 'eight']\n",
      "'green': ['unknowingly', 'umbrella', 'committee', 'ethologists', 'diagnose']\n",
      "'king': ['nicolas', 'irving', 'verlag', 'received', 'noteworthy']\n",
      "\n",
      "874000/170052070 pairs, avg loss: 0.08787, time per batch: 0.55563s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'owned']\n",
      "'his': ['gives', 'affinity', 'explains', 'society', 'determining']\n",
      "'north': ['canada', 'medical', 'health', 'workings', 'presents']\n",
      "'one': ['in', 'nine', 'old', 'zero', 'new']\n",
      "'green': ['unknowingly', 'umbrella', 'ethologists', 'diagnose', 'hendricks']\n",
      "'king': ['nicolas', 'irving', 'verlag', 'noteworthy', 'received']\n",
      "\n",
      "890000/170052070 pairs, avg loss: 0.08758, time per batch: 0.61260s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'owned']\n",
      "'his': ['gives', 'affinity', 'explains', 'services', 'determining']\n",
      "'north': ['canada', 'health', 'workings', 'medical', 'riches']\n",
      "'one': ['in', 'nine', 'provided', 'zero', 'number']\n",
      "'green': ['unknowingly', 'umbrella', 'ethologists', 'diagnose', 'hendricks']\n",
      "'king': ['nicolas', 'irving', 'verlag', 'noteworthy', 'commentator']\n",
      "\n",
      "906000/170052070 pairs, avg loss: 0.08923, time per batch: 0.56578s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'owned']\n",
      "'his': ['gives', 'affinity', 'services', 'explains', 'determining']\n",
      "'north': ['humanity', 'trait', 'canada', 'forms', 'presents']\n",
      "'one': ['in', 'nine', 'provided', 'the', 'zero']\n",
      "'green': ['unknowingly', 'umbrella', 'ethologists', 'diagnose', 'hendricks']\n",
      "'king': ['runway', 'nicolas', 'irving', 'verlag', 'noteworthy']\n",
      "\n",
      "923000/170052070 pairs, avg loss: 0.08953, time per batch: 0.55068s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'owned']\n",
      "'his': ['gives', 'affinity', 'services', 'explains', 'society']\n",
      "'north': ['growth', 'distinguished', 'trait', 'forms', 'humanity']\n",
      "'one': ['in', 'nine', 'the', 'provided', 'within']\n",
      "'green': ['unknowingly', 'umbrella', 'ethologists', 'diagnose', 'hendricks']\n",
      "'king': ['runway', 'nicolas', 'irving', 'verlag', 'noteworthy']\n",
      "\n",
      "939000/170052070 pairs, avg loss: 0.08873, time per batch: 0.57656s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'owned']\n",
      "'his': ['gives', 'affinity', 'services', 'explains', 'determining']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'north': ['forms', 'austria', 'along', 'founded', 'growth']\n",
      "'one': ['in', 'nine', 'two', 'the', 'provided']\n",
      "'green': ['unknowingly', 'umbrella', 'bruckner', 'ethologists', 'diagnose']\n",
      "'king': ['runway', 'nicolas', 'irving', 'verlag', 'noteworthy']\n",
      "\n",
      "953000/170052070 pairs, avg loss: 0.08765, time per batch: 0.59528s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'owned']\n",
      "'his': ['gives', 'affinity', 'services', 'explains', 'determining']\n",
      "'north': ['forms', 'austria', 'founded', 'effectively', 'along']\n",
      "'one': ['in', 'nine', 'two', 'the', 'old']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['runway', 'nicolas', 'sighted', 'irving', 'verlag']\n",
      "\n",
      "970000/170052070 pairs, avg loss: 0.08652, time per batch: 0.55944s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'owned']\n",
      "'his': ['gives', 'affinity', 'services', 'explains', 'determining']\n",
      "'north': ['forms', 'nations', 'austria', 'total', 'markets']\n",
      "'one': ['in', 'nine', 'two', 'the', 'old']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['runway', 'nicolas', 'sighted', 'irving', 'verlag']\n",
      "\n",
      "987000/170052070 pairs, avg loss: 0.08562, time per batch: 0.55600s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'owned']\n",
      "'his': ['services', 'gives', 'affinity', 'explains', 'determining']\n",
      "'north': ['forms', 'nations', 'desert', 'minority', 'austria']\n",
      "'one': ['in', 'the', 'two', 'nine', 'within']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['runway', 'nicolas', 'sighted', 'irving', 'verlag']\n",
      "\n",
      "1003000/170052070 pairs, avg loss: 0.08732, time per batch: 0.56006s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'owned']\n",
      "'his': ['services', 'gives', 'affinity', 'explains', 'determining']\n",
      "'north': ['nations', 'forms', 'desert', 'minority', 'austria']\n",
      "'one': ['in', 'the', 'two', 'nine', 'three']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['runway', 'nicolas', 'sighted', 'irving', 'verlag']\n",
      "\n",
      "1020000/170052070 pairs, avg loss: 0.08896, time per batch: 0.55386s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'owned']\n",
      "'his': ['services', 'gives', 'affinity', 'explains', 'determining']\n",
      "'north': ['nations', 'desert', 'few', 'minority', 'austria']\n",
      "'one': ['in', 'the', 'nine', 'within', 'two']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['runway', 'nicolas', 'sighted', 'irving', 'verlag']\n",
      "\n",
      "1037000/170052070 pairs, avg loss: 0.09082, time per batch: 0.55267s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'owned']\n",
      "'his': ['services', 'gives', 'affinity', 'explains', 'determining']\n",
      "'north': ['few', 'nations', 'desert', 'minority', 'austria']\n",
      "'one': ['in', 'the', 'within', 'nine', 'provided']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['runway', 'nicolas', 'sighted', 'irving', 'verlag']\n",
      "\n",
      "1053000/170052070 pairs, avg loss: 0.09044, time per batch: 0.56191s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'evident']\n",
      "'his': ['tis', 'nine', 'rica', 'series', 'crew']\n",
      "'north': ['few', 'nations', 'desert', 'minority', 'austria']\n",
      "'one': ['in', 'the', 'th', 'two', 'nine']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['runway', 'nicolas', 'sighted', 'irving', 'verlag']\n",
      "\n",
      "1069000/170052070 pairs, avg loss: 0.08978, time per batch: 0.55842s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'evident']\n",
      "'his': ['tis', 'rica', 'nine', 'crew', 'series']\n",
      "'north': ['nations', 'few', 'desert', 'minority', 'austria']\n",
      "'one': ['in', 'the', 'two', 'th', 'number']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['runway', 'nicolas', 'sighted', 'irving', 'verlag']\n",
      "\n",
      "1085000/170052070 pairs, avg loss: 0.08913, time per batch: 0.55334s\n",
      "'man': ['reader', 'curbed', 'jews', 'membership', 'evident']\n",
      "'his': ['tis', 'rica', 'crew', 'series', 'colonized']\n",
      "'north': ['few', 'nations', 'desert', 'forms', 'minority']\n",
      "'one': ['number', 'the', 'in', 'th', 'nine']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['runway', 'nicolas', 'sighted', 'irving', 'verlag']\n",
      "\n",
      "1102000/170052070 pairs, avg loss: 0.08845, time per batch: 0.55645s\n",
      "'man': ['politicized', 'jews', 'curbed', 'india', 'bombarding']\n",
      "'his': ['tis', 'rica', 'crew', 'series', 'colonized']\n",
      "'north': ['few', 'nations', 'desert', 'forms', 'minority']\n",
      "'one': ['number', 'the', 'in', 'nine', 'two']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['runway', 'nicolas', 'sighted', 'irving', 'verlag']\n",
      "\n",
      "1118000/170052070 pairs, avg loss: 0.08778, time per batch: 0.56826s\n",
      "'man': ['automobile', 'india', 'surveillance', 'transmitter', 'ads']\n",
      "'his': ['in', 'are', 'nine', 'the', 'sea']\n",
      "'north': ['few', 'nations', 'desert', 'forms', 'minority']\n",
      "'one': ['number', 'in', 'the', 'nine', 'two']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['runway', 'nicolas', 'sighted', 'irving', 'verlag']\n",
      "\n",
      "1134000/170052070 pairs, avg loss: 0.08736, time per batch: 0.55845s\n",
      "'man': ['automobile', 'surveillance', 'india', 'steve', 'transmitter']\n",
      "'his': ['are', 'the', 'one', 'nine', 'number']\n",
      "'north': ['few', 'nations', 'desert', 'forms', 'minority']\n",
      "'one': ['number', 'the', 'in', 'nine', 'two']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['thanks', 'testament', 'compatible', 'expression', 'trojan']\n",
      "\n",
      "1151000/170052070 pairs, avg loss: 0.08777, time per batch: 0.55117s\n",
      "'man': ['india', 'automobile', 'stories', 'transmitter', 'surveillance']\n",
      "'his': ['total', 'the', 'to', 'colonization', 'within']\n",
      "'north': ['few', 'nations', 'desert', 'forms', 'minority']\n",
      "'one': ['nine', 'th', 'zero', 'in', 'number']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['thanks', 'forever', 'convinced', 'wife', 'win']\n",
      "\n",
      "1168000/170052070 pairs, avg loss: 0.08757, time per batch: 0.58841s\n",
      "'man': ['stories', 'india', 'automobile', 'transmitter', 'surveillance']\n",
      "'his': ['in', 'he', 'nine', 'one', 'to']\n",
      "'north': ['few', 'nations', 'desert', 'forms', 'minority']\n",
      "'one': ['nine', 'in', 'his', 'two', 'the']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['thanks', 'forever', 'convinced', 'wife', 'trojan']\n",
      "\n",
      "1184000/170052070 pairs, avg loss: 0.08794, time per batch: 0.57548s\n",
      "'man': ['stories', 'india', 'automobile', 'transmitter', 'strict']\n",
      "'his': ['in', 'he', 'to', 'two', 'at']\n",
      "'north': ['few', 'nations', 'desert', 'aggressive', 'forms']\n",
      "'one': ['nine', 'in', 'seven', 'his', 'two']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['thanks', 'forever', 'convinced', 'wife', 'channel']\n",
      "\n",
      "1200000/170052070 pairs, avg loss: 0.08794, time per batch: 0.56118s\n",
      "'man': ['stories', 'india', 'automobile', 'strict', 'transmitter']\n",
      "'his': ['in', 'he', 'after', 'two', 'agassi']\n",
      "'north': ['few', 'nations', 'desert', 'aggressive', 'along']\n",
      "'one': ['nine', 'in', 'seven', 'thriller', 'two']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['thanks', 'forever', 'convinced', 'wife', 'channel']\n",
      "\n",
      "1216000/170052070 pairs, avg loss: 0.08838, time per batch: 0.55358s\n",
      "'man': ['stories', 'india', 'automobile', 'third', 'strict']\n",
      "'his': ['in', 'he', 'after', 'two', 'agassi']\n",
      "'north': ['few', 'nations', 'desert', 'along', 'aggressive']\n",
      "'one': ['nine', 'in', 'seven', 'two', 'federer']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['thanks', 'forever', 'convinced', 'wife', 'channel']\n",
      "\n",
      "1232000/170052070 pairs, avg loss: 0.09475, time per batch: 0.55441s\n",
      "'man': ['india', 'stories', 'third', 'automobile', 'idea']\n",
      "'his': ['in', 'he', 'after', 'two', 'to']\n",
      "'north': ['few', 'nations', 'desert', 'along', 'aggressive']\n",
      "'one': ['nine', 'in', 'seven', 'two', 'federer']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['forever', 'trojan', 'thanks', 'expression', 'testament']\n",
      "\n",
      "1247000/170052070 pairs, avg loss: 0.09416, time per batch: 0.62552s\n",
      "'man': ['india', 'stories', 'third', 'automobile', 'demographics']\n",
      "'his': ['in', 'he', 'after', 'to', 'two']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'north': ['few', 'nations', 'desert', 'along', 'aggressive']\n",
      "'one': ['nine', 'in', 'seven', 'two', 'federer']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['testament', 'compatible', 'computers', 'trojan', 'expression']\n",
      "\n",
      "1262000/170052070 pairs, avg loss: 0.09359, time per batch: 0.58285s\n",
      "'man': ['india', 'stories', 'third', 'demographics', 'automobile']\n",
      "'his': ['in', 'he', 'after', 'to', 'two']\n",
      "'north': ['few', 'nations', 'desert', 'along', 'aggressive']\n",
      "'one': ['nine', 'in', 'seven', 'two', 'federer']\n",
      "'green': ['bruckner', 'unknowingly', 'umbrella', 'schubert', 'ethologists']\n",
      "'king': ['compatible', 'computers', 'testament', 'sons', 'expression']\n",
      "\n",
      "1278000/170052070 pairs, avg loss: 0.09277, time per batch: 0.55543s\n",
      "'man': ['india', 'stories', 'third', 'worn', 'demographics']\n",
      "'his': ['in', 'he', 'after', 'to', 'agassi']\n",
      "'north': ['few', 'nations', 'along', 'aggressive', 'minority']\n",
      "'one': ['nine', 'in', 'seven', 'six', 'federer']\n",
      "'green': ['bruckner', 'umbrella', 'unknowingly', 'diagnose', 'tyrranion']\n",
      "'king': ['compatible', 'computers', 'testament', 'sons', 'expression']\n",
      "\n",
      "1291000/170052070 pairs, avg loss: 0.09208, time per batch: 1.60819s\n",
      "'man': ['india', 'stories', 'third', 'demographics', 'worn']\n",
      "'his': ['in', 'he', 'to', 'after', 'federer']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-2441cb72e6f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m embeddings_matrix = train_network(inputs_placeholder, targets_placeholder, weights_1,\n\u001b[1;32m      4\u001b[0m                                   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_stream_builder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                   train_pairs_estimated, words)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-bd141a39d526>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(inputs_placeholder, targets_placeholder, weights_1, loss, train_stream_builder, epochs, learning_rate, total_pairs, words)\u001b[0m\n\u001b[1;32m     28\u001b[0m                                                      time_end - time_start)\n\u001b[1;32m     29\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0mtest_analogies_quality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mtime_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-f4bf797792f6>\u001b[0m in \u001b[0;36mtest_analogies_quality\u001b[0;34m(words, embeddings_matrix)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtest_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"man\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"his\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"north\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"one\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"green\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"king\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarities_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0msimilarities_short\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'{}': {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities_short\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-abed6d2e035f>\u001b[0m in \u001b[0;36mcosine_similarities_s\u001b[0;34m(words, embeddings_matrix, s)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mterm_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilarities\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterm_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f03a8d33cbfa>\u001b[0m in \u001b[0;36mcosine_similarities\u001b[0;34m(words, embeddings_matrix, vector)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/progs/word2vec_env/lib/python3.5/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             (ord == 2 and ndim == 1)):\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network = build_network(vocab_size, embedding_size, num_samples)\n",
    "inputs_placeholder, targets_placeholder, loss, weights_1 = network\n",
    "embeddings_matrix = train_network(inputs_placeholder, targets_placeholder, weights_1,\n",
    "                                  loss, train_stream_builder, epochs, learning_rate,\n",
    "                                  train_pairs_estimated, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(words, embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_analogies_quality(words, embeddings_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
